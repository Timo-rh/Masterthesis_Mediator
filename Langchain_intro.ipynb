{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T13:18:00.481898Z",
     "start_time": "2025-05-09T13:17:56.262038Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "output = llm.invoke(\"Was ist der Unterschied zwischen Machine Learning und KI?\") #invoke ruft prompt auf\n",
    "\n",
    "print(output.content)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T09:07:51.015107Z",
     "start_time": "2025-05-05T09:07:49.348662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([    (\"system\", \"Du bist ein hilfsbereiter Assistent.\"),\n",
    "                                               (\"human\", \"Erkläre den Begriff {term} in einfachen Worten.\")])\n",
    "\n",
    "chain = prompt | llm\n",
    "output = chain.invoke({\"term\" : \"Chain in LangChain\"})\n",
    "\n",
    "print(output.content)"
   ],
   "id": "e26e80311a7fc4a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein Chain in LangChain ist eine Reihe von Ereignissen oder Aktionen, die miteinander verbunden sind und aufeinander folgen. Es ist wie eine Kette, bei der ein Glied mit dem nächsten verbunden ist und alles zusammenhält. In LangChain wird dieses Konzept verwendet, um eine Abfolge von Prozessen oder Entscheidungen darzustellen, die zu einem bestimmten Ergebnis führen.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T09:15:15.430677Z",
     "start_time": "2025-05-05T09:15:14.172890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([    (\"system\", \"Du bist ein hilfsbereiter Assistent.\"),\n",
    "                                               (\"human\", \"Erkläre den Begriff {term} in einfachen Worten.\")])\n",
    "\n",
    "\n",
    "output_parser = RunnableLambda(lambda llm_output : llm_output.content) #lambda definiert funktion\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "output = chain.invoke({\"term\" : \"Chain in LangChain\"})\n",
    "print(output)"
   ],
   "id": "c2a09b8300f82729",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In LangChain bedeutet \"Chain\" Verkettung oder Verbindung von verschiedenen Elementen in einer bestimmten Reihenfolge. Es symbolisiert die Verbindung von verschiedenen Sprachen oder Kulturen in einem Netzwerk.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1307ee33075a36"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
